{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here's a copy of my docker-compose.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "---\n",
    "version: '2'\n",
    "services:\n",
    "  zookeeper:\n",
    "    image: confluentinc/cp-zookeeper:latest\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 32181\n",
    "      ZOOKEEPER_TICK_TIME: 2000\n",
    "    expose:\n",
    "      - \"2181\"\n",
    "      - \"2888\"\n",
    "      - \"32181\"\n",
    "      - \"3888\"\n",
    "\n",
    "  kafka:\n",
    "    image: confluentinc/cp-kafka:latest\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    environment:\n",
    "      KAFKA_BROKER_ID: 1\n",
    "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181\n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "    expose:\n",
    "      - \"9092\"\n",
    "      - \"29092\"\n",
    "\n",
    "  cloudera:\n",
    "    image: midsw205/cdh-minimal:latest\n",
    "    expose:\n",
    "      - \"8020\" # nn\n",
    "      - \"50070\" # nn http\n",
    "\n",
    "  spark:\n",
    "    image: midsw205/spark-python:0.0.5\n",
    "    ports:\n",
    "    - \"8888:8888\"\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    volumes:\n",
    "      - ~/w205:/w205\n",
    "    command: bash\n",
    "    depends_on:\n",
    "      - cloudera\n",
    "    environment:\n",
    "      HADOOP_NAMENODE: cloudera\n",
    "\n",
    "  mids:\n",
    "    image: midsw205/base:latest\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    volumes:\n",
    "      - ~/w205:/w205\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of docker-compose.yml\n",
    "The docker-compose.yml defines how multiple containers run and interact with one another. The innermost indent after services lists the containers/services that will be launched and coordinated. Some of the `ports` and `expose` instructions define how the containers communicate with one another while other define how they communicate with other services.   \n",
    "\n",
    "- **zookeeper:**Is a service that, in our case, coordinates the use of kafka's topics and brokers. When we create a topic in kafka we register it in zookeeper because kafka doesn't have an overview of topic and broker relationships itself. kafka communicates with zookeeper on port 32181.\n",
    "   \n",
    "\n",
    "- **kafka:** kafka is a distributed system that Doris analogized to Slack. kafka can intake messages (\"publish\" or \"produce\" to kafka) to \"topics\" we define. The messages are placed in a queue associated with that topic. Once there, the data can be read (\"consumed\") by subscribers to those topics. In our case, spark is a subscriber to the topics we're creating. In the instructions that follow you'll see messages written to ('produced') and read from ('consumed') on port 29092, which is the port exposed in the above yml file under kafka for that purpose.  \n",
    "\n",
    "  \n",
    "- **cloudera:** In our case, cloudera is providing us with a Hadoop instance. Hadoop is a distributed data store that we'll write our data to.   \n",
    "\n",
    "  \n",
    "- **spark:** Spark is the analytics engine we use for this project. It's the tool within which we unpack the nested assessment json and where we run our SQL queries. We've modified our docker-compose file to allow jupyter notebooks to communicate with spark on port 8888. We've also mapped, under 'volumes', the virtual machine's w205 folder to a corresponding one inside the spark container.  \n",
    "\n",
    "\n",
    "- **mids:** Services like the jupyter notebooks and kafkacat are provided by the mids image. Similar to the spark container, we've mapped the virtual machine's w205 folder to a corresponding one inside the mids container. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-by-Step of getting data from the json and into kafka, all of which takes place on the commmand line and is in the history.txt file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spin up the cluster using the information in the docker-compose.yml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```docker-compose up -d```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out hadoop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker-compose exec cloudera hadoop fs -ls /tmp/```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an assessments topic in kafka. Let zookeeper know . "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker-compose exec kafka kafka-topics --create --topic assessments --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipe assessments.json into jq. Use the iterator command [] along with the switch -c to send individual elements of the nested JSON into kafkacat. kafkacat will take those lines and produce/publish those lines into kafka using the port 29092 to the topic assessments we create above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker-compose exec mids bash -c \"cat /w205/project-2-FuriousGeorge19/assessments.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t assessments\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following command to grant a previously created Jupyter notebook access to Spark through port 8888. We modified the docker-compose.yml to allow access through this port. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root --notebook-dir=/w205/' pyspark```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch over to the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The prior command has made pyspark available in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### import libraries to enable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F \n",
    "from pyspark.sql.functions import from_json, col, lit, countDistinct, avg, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, LongType\n",
    "import sys \n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read assessments data from kafka into a pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_assessments = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:29092\").option(\"subscribe\",\"assessments\").option(\"startingOffsets\", \"earliest\").option(\"endingOffsets\", \"latest\").load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_assessments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cache the dataframe to cut back on warnings and make queries faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_assessments.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check count to make sure data was written properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assessments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments = raw_assessments.select(raw_assessments.value.cast('string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract json fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_assessments = spark.read.json(assessments.rdd.map(lambda x: x.value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a temp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_assessments.registerTempTable('assessments_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the structure by looking at the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- certification: string (nullable = true)\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- keen_created_at: string (nullable = true)\n",
      " |-- keen_id: string (nullable = true)\n",
      " |-- keen_timestamp: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: long (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: long (nullable = true)\n",
      " |    |    |-- incomplete: long (nullable = true)\n",
      " |    |    |-- incorrect: long (nullable = true)\n",
      " |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |-- total: long (nullable = true)\n",
      " |    |    |-- unanswered: long (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- user_submitted: boolean (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- user_exam_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only sequences is nested. But it is really, really nested and will take a bit of work to pick apart and understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at unnested columns first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+------------------+\n",
      "|        base_exam_id|certification|           exam_name|   keen_created_at|\n",
      "+--------------------+-------------+--------------------+------------------+\n",
      "|37f0a30a-7464-11e...|        false|Normal Forms and ...| 1516717442.735266|\n",
      "|37f0a30a-7464-11e...|        false|Normal Forms and ...| 1516717377.639827|\n",
      "|4beeac16-bb83-4d5...|        false|The Principles of...| 1516738973.653394|\n",
      "|4beeac16-bb83-4d5...|        false|The Principles of...|1516738921.1137421|\n",
      "|6442707e-7488-11e...|        false|Introduction to B...| 1516737000.212122|\n",
      "+--------------------+-------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select base_exam_id, certification, exam_name, keen_created_at from assessments_df limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------+--------------------+--------------------+\n",
      "|             keen_id|    keen_timestamp|max_attempts|          started_at|        user_exam_id|\n",
      "+--------------------+------------------+------------+--------------------+--------------------+\n",
      "|5a6745820eb8ab000...| 1516717442.735266|         1.0|2018-01-23T14:23:...|6d4089e4-bde5-4a2...|\n",
      "|5a674541ab6b0a000...| 1516717377.639827|         1.0|2018-01-23T14:21:...|2fec1534-b41f-441...|\n",
      "|5a67999d3ed3e3000...| 1516738973.653394|         1.0|2018-01-23T20:22:...|8edbc8a8-4d26-429...|\n",
      "|5a6799694fc7c7000...|1516738921.1137421|         1.0|2018-01-23T20:21:...|c0ee680e-8892-4e6...|\n",
      "|5a6791e824fccd000...| 1516737000.212122|         1.0|2018-01-23T19:48:...|e4525b79-7904-405...|\n",
      "+--------------------+------------------+------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select keen_id, keen_timestamp, max_attempts, started_at, user_exam_id from assessments_df limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll do a little exploration to see what these fields might mean. I'll start w/base_exam_id and exam_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select base_exam_id, exam_name from assessments_df limit 10\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### base_exam_id appears like it might be the unique key associated with exam_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT exam_name)|\n",
      "+-------------------------+\n",
      "|                      103|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct(\"exam_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT base_exam_id)|\n",
      "+----------------------------+\n",
      "|                         107|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct(\"base_exam_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With more time and a stronger knowledge of sql I'd select for exam_name's that matched each other but exam_id's that did not. But using groupby and scanning was quicker in this case as it's only 107 rows long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = assessments_df.select('base_exam_id','exam_name').groupby('base_exam_id','exam_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------------------------------------------------------------+-----+\n",
      "|base_exam_id                        |exam_name                                                              |count|\n",
      "+------------------------------------+-----------------------------------------------------------------------+-----+\n",
      "|f432e2e3-7e3a-4a78-b408-49cab5d1fbeb|Working with Algorithms in Python                                      |14   |\n",
      "|e9b58c58-bf2e-4bde-be81-52fb02ebc892|What's New in JavaScript                                               |2    |\n",
      "|98a4b6fd-7460-11e6-b6c2-a4d18ccf3cb4|Web & Native Working Together                                          |8    |\n",
      "|44d5ca66-7462-11e6-9d9f-a8667f27e5dc|View Updating                                                          |4    |\n",
      "|30fd83f9-4937-4a00-bcf3-42e495fecd55|Using Web Components                                                   |3    |\n",
      "|b71d9e1e-7525-11e6-927c-a4d18ccf3cb4|Using Storytelling to Effectively Communicate Data                     |4    |\n",
      "|526908f1-9c67-4ab4-9882-a87973374a3b|Using R for Big Data with Spark                                        |24   |\n",
      "|1daab041-cdd9-4287-b6b8-ed55b32153e6|Understanding the Grails 3 Domain Model                                |2    |\n",
      "|4beeac16-bb83-4d58-83e4-26cdc38f0481|The Principles of Microservices                                        |11   |\n",
      "|f224b886-745e-11e6-8f07-a8667f27e5dc|The Closed World Assumption                                            |2    |\n",
      "|8fcb41f8-76ac-11e6-99b2-9801a7c3b233|TCP/IP                                                                 |21   |\n",
      "|b0011798-80dd-4cb2-988c-23239e9d52c2|Starting a Grails 3 Project                                            |5    |\n",
      "|ad6ad93e-0d28-47e3-b655-1cf8852b254e|Software Architecture Fundamentals Understanding the Basics            |109  |\n",
      "|ca00f150-41b3-41c0-8d64-372c631a8244|Software Architecture Fundamentals Beyond The Basics                   |48   |\n",
      "|a2be982d-5391-4f19-af0f-1fb47a259c6c|Service Based Architectures                                            |3    |\n",
      "|ee5b6f14-709d-11e6-b75b-a8667f27e5dc|SQL: Beyond the Basics                                                 |11   |\n",
      "|be722e22-6b18-4c4b-9547-6fe75c218f99|Reproducible Research and Reports with R Markdown                      |21   |\n",
      "|9fd6c9e2-709f-11e6-8871-a8667f27e5dc|Relational Theory for Computer Professionals                           |15   |\n",
      "|95c09e8f-6292-4471-b939-5ba87c3c62ff|Refactor a Monolithic Architecture into Microservices                  |17   |\n",
      "|a7a65ec6-77dc-480d-9926-dd0012677829|Python Epiphanies                                                      |51   |\n",
      "|e5602ceb-6f0d-11e6-8aff-9801a7c3b233|Python Data Structures                                                 |29   |\n",
      "|786af9ee-7153-11e6-b53e-a4d18ccf3cb4|Practical Java Programming                                             |53   |\n",
      "|3aa9edb7-6031-41f9-b07e-2380ae6b857a|Operating Red Hat Enterprise Linux Servers                             |1    |\n",
      "|f67fc173-7460-11e6-8f77-a4d18ccf3cb4|Offline Web                                                            |13   |\n",
      "|b0117330-7461-11e6-a8f1-a8667f27e5dc|Nulls, Three-valued Logic and Missing Information                      |1    |\n",
      "|4ea9383e-745d-11e6-94c4-a8667f27e5dc|Nullology                                                              |8    |\n",
      "|37f0a30a-7464-11e6-aa92-a8667f27e5dc|Normal Forms and All That Jazz Master Class                            |7    |\n",
      "|8e23138f-8a50-4f69-ad87-6b46c89a2153|Networking for People Who Hate Networking                              |15   |\n",
      "|13013db3-7461-11e6-8054-a4d18ccf3cb4|Native Web Apps for Android                                            |1    |\n",
      "|f83fae20-8d97-40d7-b4d5-23e5725d2d4d|Modeling for Software Architects                                       |5    |\n",
      "|ffc5c454-7460-11e6-bea1-a4d18ccf3cb4|Mastering Web Views                                                    |3    |\n",
      "|dd9e3175-45a4-4913-b1d2-1f64e183fc53|Mastering Python - Networking and Security                             |25   |\n",
      "|5d0f436c-ec7b-4269-95e2-825946a026ee|Mastering Git                                                          |77   |\n",
      "|4b546345-b897-4184-af39-21eb9d6c0321|Mastering Advanced Git                                                 |34   |\n",
      "|3528cd24-01a4-47e8-b2cf-c4b54e143284|Learning to Visualize Data with D3.js                                  |1    |\n",
      "|b114e4a4-a192-4dff-a5cd-8e7782bb1623|Learning to Program with R                                             |128  |\n",
      "|76a682de-6f0c-11e6-b36d-9801a7c3b233|Learning iPython Notebook                                              |17   |\n",
      "|3472e558-8f0f-4be4-a57d-30edfbd181de|Learning Spring Programming                                            |2    |\n",
      "|cc2dac54-709b-11e6-8b35-a8667f27e5dc|Learning SQL for Oracle                                                |11   |\n",
      "|a3cf5a0f-6bd8-11e6-8d83-a8667f27e5dc|Learning SQL                                                           |57   |\n",
      "|a62e5d35-75e9-11e6-8197-9801a7c3b233|Learning Linux System Administration                                   |59   |\n",
      "|76f39b28-76be-11e6-ae8a-9801a7c3b233|Learning Linux Security                                                |27   |\n",
      "|05a30b30-0465-42ef-b5d7-598e61840025|Learning Java EE 7                                                     |25   |\n",
      "|8b4488de-43a5-4ffa-bf82-af1e19ee1b64|Learning Git                                                           |394  |\n",
      "|f3f88f87-7151-11e6-ba4a-a4d18ccf3cb4|Learning Eclipse                                                       |85   |\n",
      "|0e556c3d-199e-44e6-9fae-0e8b54b6444f|Learning Data Structures and Algorithms                                |13   |\n",
      "|479f39cc-70a9-11e6-a73e-a8667f27e5dc|Learning Data Modeling                                                 |9    |\n",
      "|b2264d14-7699-11e6-b275-9801a7c3b233|Learning DNS                                                           |40   |\n",
      "|a8dedd1d-0f67-4f4c-a41e-763dbb764493|Learning C# Design Patterns                                            |23   |\n",
      "|56c8b891-0d34-4a87-b2aa-9de816823784|Learning C# Best Practices                                             |35   |\n",
      "|846364d4-7153-11e6-9ab8-a4d18ccf3cb4|Learning Apache Maven                                                  |80   |\n",
      "|417d1748-76ab-11e6-ae96-a8667f27e5dc|Learning Apache Hadoop                                                 |16   |\n",
      "|dff2ec2e-79f6-11e6-a4fc-a8667f27e5dc|Learning Apache Cassandra                                              |12   |\n",
      "|77ba773a-715e-11e6-899f-a4d18ccf3cb4|JavaScript: The Good Parts Master Class with Douglas Crockford         |58   |\n",
      "|8adc4a4f-715e-11e6-a6b8-a4d18ccf3cb4|JavaScript Templating                                                  |21   |\n",
      "|6672aad3-934b-4265-9417-15e8e903a48d|Introduction to Time Series with Team Apache                           |28   |\n",
      "|9bcbb38f-c017-498a-976d-9a3bb889f79b|Introduction to Shiny                                                  |27   |\n",
      "|747d6bf1-4c14-438f-b85f-e1111ccc4b15|Introduction to Python                                                 |40   |\n",
      "|7e2e0b53-a7ba-458d-8bc6-356f8dea8815|Introduction to Python                                                 |122  |\n",
      "|87b4b3f9-3a86-435e-8360-25379c6978ca|Introduction to Modern Front-End Development                           |6    |\n",
      "|30165eb8-4429-433d-90a8-affe7c780766|Introduction to Modern Client-Side Programming                         |13   |\n",
      "|c464bf80-6bca-11e6-a9a9-a8667f27e5dc|Introduction to Machine Learning                                       |119  |\n",
      "|41858ac3-1394-451b-bf7c-c10f52034a9a|Introduction to Java 8                                                 |158  |\n",
      "|1d2a2d14-7484-11e6-9444-a8667f27e5dc|Introduction to Hadoop YARN                                            |8    |\n",
      "|7b398106-8b73-4e73-b133-edff27cd6904|Introduction to Data Science with R                                    |43   |\n",
      "|6442707e-7488-11e6-831b-a8667f27e5dc|Introduction to Big Data                                               |75   |\n",
      "|0161dadc-748e-11e6-bcd0-a4d18ccf3cb4|Introduction to Architecting Amazon Web Services                       |14   |\n",
      "|d46f46ea-de56-4fd3-a578-9642ff4c3665|Introduction to Apache Spark                                           |9    |\n",
      "|d944b130-46a0-455b-b721-92de373afd71|Introduction to Apache Kafka                                           |13   |\n",
      "|5ff1ceda-7485-11e6-ba39-a8667f27e5dc|Introduction to Apache Hive                                            |7    |\n",
      "|f9de34a3-748d-11e6-a58a-a4d18ccf3cb4|Introduction to Amazon Web Services (AWS) - EC2 Deployment Fundamentals|6    |\n",
      "|1a233da8-e6e5-48a6-8c3c-806e312cce12|Intermediate Python Programming                                        |158  |\n",
      "|94b741b2-fc67-4db4-adc2-aafae130848f|Intermediate C# Programming                                            |43   |\n",
      "|f80366d9-db60-41c3-a1c4-6c7789b478f8|I'm a Software Architect, Now What?                                    |15   |\n",
      "|0953542c-e6b4-46cf-a0c2-958a914c2715|Hibernate and JPA Fundamentals                                         |2    |\n",
      "|b4da3808-7474-11e6-a15c-a8667f27e5dc|Hadoop Fundamentals for Data Scientists                                |6    |\n",
      "|8aaa9a07-1e0a-47b0-9146-f3310e018e61|HTML5 The Basics                                                       |52   |\n",
      "|16c98e57-76bc-11e6-a7d7-9801a7c3b233|Great Bash                                                             |6    |\n",
      "|0fed9e6e-6438-4644-a59d-e581e844d5e2|Great Bash                                                             |8    |\n",
      "|e1f07fac-5566-4fdd-95e0-b6aa06fd5b50|Git Fundamentals for Web Developers                                    |28   |\n",
      "|2000fbc1-32b8-41cd-b794-da01b1aedae7|Getting Ready for Angular 2                                            |3    |\n",
      "|f957412c-b316-4fa1-8af4-cfcdb5ad1e63|Expert Data Wrangling with R                                           |35   |\n",
      "|example-id                          |Example Exam For Development and Testing oh yeahsdf                    |5    |\n",
      "|0678c2d4-f70d-4aa1-ae3a-59b3bb8f5725|Event-Driven Microservices                                             |10   |\n",
      "|500c5332-2ab4-4f65-9cd9-80420c2d4012|Design Patterns in Java                                                |15   |\n",
      "|5a1a0072-47c5-4789-abf1-a38c7d75716d|Data Visualization in R with ggplot2                                   |31   |\n",
      "|4df97d5f-4f98-4d1e-9270-9a0bbd9bb60e|Data Science with Microsoft Azure and R                                |7    |\n",
      "|615d8873-5947-48c0-bc4e-01069a0b2d20|Collaborating with Git                                                 |6    |\n",
      "|2cac6396-6c41-11e7-a76e-6b377f1287a6|Cloud Native Architecture Fundamentals                                 |29   |\n",
      "|dac38d07-748d-11e6-afe6-a4d18ccf3cb4|Cloud Computing With AWS                                               |17   |\n",
      "|d56d0878-1b66-45a9-a743-d280e8b4a791|Client-Side Data Storage for Web Developers                            |2    |\n",
      "|addea30d-949c-4c30-a562-fc231b1c3f7c|Building Web Services with Java                                        |3    |\n",
      "|392651a1-e62f-4e72-b7dd-88df2253bc49|Being a Better Introvert                                               |2    |\n",
      "|ee725ec8-d26b-4263-b8aa-c76592d1edf4|Being a Better Introvert                                               |8    |\n",
      "|9547a6eb-715e-11e6-9b72-a4d18ccf3cb4|Beginning Programming with JavaScript                                  |79   |\n",
      "|1afec2b2-6178-4ce7-8154-5f0c9a3959c9|Beginning C# Programming                                               |95   |\n",
      "|c2b52796-0dad-4e08-a40f-b2081dd965db|Arduino Prototyping Techniques                                         |2    |\n",
      "|1ec46a4c-c038-4bd1-b730-09557635ecbf|Arduino Prototyping Basics                                             |10   |\n",
      "|beec531b-e87e-4ab7-ab2a-02c03dff3676|Arduino Inputs                                                         |8    |\n",
      "|b205eb22-7b95-11e6-84f8-a8667f27e5dc|Architectural Considerations for Hadoop Applications                   |3    |\n",
      "|39365c35-f99a-4b59-8ba9-c511350f090a|Architectural Considerations for Hadoop Applications                   |7    |\n",
      "|9ff51f14-7525-11e6-a5b2-a4d18ccf3cb4|An Introduction to d3.js: From Scattered to Scatterplot                |33   |\n",
      "|e700d410-7460-11e6-8afe-a8667f27e5dc|An Introduction to Set Theory                                          |5    |\n",
      "|e5fee01e-748d-11e6-9470-a4d18ccf3cb4|Amazon Web Services - Virtual Private Cloud                            |11   |\n",
      "|f0633ed7-748d-11e6-853c-a4d18ccf3cb4|Amazon Web Services - Simple Storage Service                           |12   |\n",
      "|e824836a-3835-4e79-b070-ae6d0da89b3e|Advanced Machine Learning                                              |67   |\n",
      "|4cdf9b5f-fdb7-4a4f-aaf3-51ec08dedecb|A Practical Introduction to React.js                                   |9    |\n",
      "+------------------------------------+-----------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.sort(\"exam_name\", ascending = False).show(107, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It turns out 4 exams show up twice in exam_name but with unique ID's. Those are \n",
    "- Introduction to Python  \n",
    "- Great Bash  \n",
    "- Architectural Considerations for Hadoop Applications  \n",
    "- Being a Better Introvert\n",
    "\n",
    "I'd include both columns in the dataset, but provide some notes in a README alerting analysts to the fact that 'exam_name' and 'base_exam_id' are almost, but not quite, 1 to 1 matches and ask whether, if they are indeed meant to be unique, if they should be consolidated under a single id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments_df.select(countDistinct(\"user_exam_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll perform a similar exercise with user_exam_id.\n",
    "#### We'll start by looking to see if the user_exam_id's are unique, knowing there are 3280 rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT user_exam_id)|\n",
      "+----------------------------+\n",
      "|                        3242|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct(\"user_exam_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not quite unique. But pretty close. I'll take a look to see if the discrepancy is due to NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_df.filter(assessments_df[\"user_exam_id\"].isNull()).select('user_exam_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The discrepancy doesn't look like it's due to NULLs, but potentially due to repeats. As this is likely 'the most unique' of the IDs, if I were to split this table, user_exam_id would be the most likely candidate to serve as a common key between the tables. Given more time, I'd want to dig into why there are repeats, if they should be renumbered and retained or if they should be dropped from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last potential candidate as a unique key is keen_id. We'll take a quick look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT keen_id)|\n",
      "+-----------------------+\n",
      "|                   3242|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct(\"keen_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This has the same number of unique id's as user_exam_id. As I have a clearer understanding of what user_exam_id is than keen_id, I'll use the former as a key if I were to split the table at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'll move on to looking at the data nested under 'sequences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll print the part of the schema associated with sequences so we don't have to scroll so far up to review it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: long (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: long (nullable = true)\n",
      " |    |    |-- incomplete: long (nullable = true)\n",
      " |    |    |-- incorrect: long (nullable = true)\n",
      " |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |-- total: long (nullable = true)\n",
      " |    |    |-- unanswered: long (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- user_submitted: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select('sequences').printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start by looking at 'sequences.attempt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|attempt|\n",
      "+-------+\n",
      "|      1|\n",
      "|      1|\n",
      "|      1|\n",
      "|      1|\n",
      "|      1|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select('sequences.attempt').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|count(DISTINCT sequences.attempt)|\n",
      "+---------------------------------+\n",
      "|                                1|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct('sequences.attempt')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_df.select(F.sum('sequences.attempt')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the values in 'sequences.attempt' are 1. I'm not sure this tells us much that is useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll next look to 'sequences.counts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+----------+---------+-----+\n",
      "|correct|incorrect|incomplete|unanswered|submitted|total|\n",
      "+-------+---------+----------+----------+---------+-----+\n",
      "|      2|        1|         1|         0|        4|    4|\n",
      "|      1|        1|         2|         0|        4|    4|\n",
      "|      3|        1|         0|         0|        4|    4|\n",
      "|      2|        0|         2|         0|        4|    4|\n",
      "|      3|        1|         0|         0|        4|    4|\n",
      "|      5|        0|         0|         0|        5|    5|\n",
      "|      1|        0|         0|         0|        1|    1|\n",
      "|      5|        0|         0|         0|        5|    5|\n",
      "|      4|        0|         0|         0|        4|    4|\n",
      "|      0|        0|         1|         4|        1|    5|\n",
      "|      3|        0|         1|         0|        4|    4|\n",
      "|      1|        0|         0|         0|        1|    1|\n",
      "|      4|        1|         1|         0|        6|    6|\n",
      "|      4|        2|         0|         0|        6|    6|\n",
      "|      4|        0|         1|         0|        5|    5|\n",
      "|      3|        1|         0|         0|        4|    4|\n",
      "|      3|        0|         0|         1|        3|    4|\n",
      "|      4|        0|         0|         0|        4|    4|\n",
      "|      2|        0|         0|         2|        2|    4|\n",
      "|      6|        0|         0|         0|        6|    6|\n",
      "+-------+---------+----------+----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(\"sequences.counts.correct\", \"sequences.counts.incorrect\", \\\n",
    "                      \"sequences.counts.incomplete\",\"sequences.counts.unanswered\",\\\n",
    "                      \"sequences.counts.submitted\", \"sequences.counts.total\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assessments_df.select(\"sequences.counts.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are definitely interesting data and should be part of what's available to the analysts.\n",
    "It would appear these are the test scores. 'correct' and 'total' in particular would seem to be what you'd need to calculate \n",
    "a percentage correct when evaluating an assessment result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll next look at 'sequences.id.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7a2ed6d3-f492-49b3-b8aa-d080a8aad986',\n",
       " 'bbed4358-999d-4462-9596-bad5173a6ecb',\n",
       " 'e6ad8644-96b1-4617-b37b-a263dded202c',\n",
       " '95194331-ac43-454e-83de-ea8913067055']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are these the IDs of the questions taken?\n",
    "assessments_df.select('sequences.questions.id').take(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|size(sequences.questions.id)|total|\n",
      "+----------------------------+-----+\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           5|    5|\n",
      "|                           1|    1|\n",
      "|                           5|    5|\n",
      "|                           4|    4|\n",
      "|                           5|    5|\n",
      "|                           4|    4|\n",
      "|                           1|    1|\n",
      "|                           6|    6|\n",
      "|                           6|    6|\n",
      "|                           5|    5|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           4|    4|\n",
      "|                           6|    6|\n",
      "+----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This seems to tie out the # of IDs to the total number of questions (below)\n",
    "assessments_df.select(F.size('sequences.questions.id'), 'sequences.counts.total').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'sequences.questions.id' appears to be an array of question ID's. As a check, I compared the length of the array to the total question count. They appear to match up exactly. I would certainly keep this in the data passed to analysts as it could be used to join on unique question information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last piece I'll tackle is 'sequences.questions', which is the most complex and most nested portion of the dataset. I'll only touch on it briefly. The key question I have w/r/t this data is what is in this portion of the dataset that is not reflected elsewhere? It appears to have per question, per assessment information. (i.i.e. Which particular questions on a particular assesment taken by a person were correct, incorrect, etc.?)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           questions|\n",
      "+--------------------+\n",
      "|[[7a2ed6d3-f492-4...|\n",
      "|[[95194331-ac43-4...|\n",
      "|[[b9ff2e88-cf9d-4...|\n",
      "|[[1f7c5def-904b-4...|\n",
      "|[[620c924f-6bd8-1...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select('sequences.questions').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(at='2018-01-23T14:23:24.670Z', checked=True, correct=True, id='49c574b4-5c82-4ffd-9bd1-c3358faf850d', submitted=1)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_df.select('sequences.questions.options').take(1)[0][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A fairly typical row appears above. It seems like this data might be redundant with some of the data captured in other fields. If I were to spend more time with this dataset, one thing I would want to make clearer is what do all the different id's mean. I'd relabel them to make them clearer. (i.e. assessment_id, question_id, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: long (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: long (nullable = true)\n",
      " |    |    |-- incomplete: long (nullable = true)\n",
      " |    |    |-- incorrect: long (nullable = true)\n",
      " |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |-- total: long (nullable = true)\n",
      " |    |    |-- unanswered: long (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- user_submitted: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select('sequences').printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### QUERIES USING THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. How many assessments are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If each row is an assessment, then there were 3,280 assessments in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. How many people took Learning Git?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_df.filter(assessments_df[\"exam_name\"] == \"Learning Git\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "394 people took 'Learning Git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the least common course taken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "course_counts = assessments_df.select('exam_name').groupBy(\"exam_name\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_course = course_counts.select('exam_name').groupBy(\"exam_name\").count().agg({'count':'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----+\n",
      "|exam_name                                        |count|\n",
      "+-------------------------------------------------+-----+\n",
      "|Learning to Visualize Data with D3.js            |1    |\n",
      "|Nulls, Three-valued Logic and Missing Information|1    |\n",
      "|Native Web Apps for Android                      |1    |\n",
      "|Operating Red Hat Enterprise Linux Servers       |1    |\n",
      "+-------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course_counts.filter(course_counts[\"count\"] == min_course.collect()[0][0] ).show(course_counts.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 least commonly taken courses are above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the most commonly course taken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|exam_name   |count|\n",
      "+------------+-----+\n",
      "|Learning Git|394  |\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course_counts.filter(course_counts[\"count\"] == max_course.collect()[0][0] ).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly taken course is above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. How would I determine the score (= percent correct) for each assessment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|pct_correct|\n",
      "+-----------+\n",
      "|        0.5|\n",
      "|       0.25|\n",
      "|       0.75|\n",
      "|        0.5|\n",
      "|       0.75|\n",
      "|        1.0|\n",
      "|        1.0|\n",
      "|        1.0|\n",
      "|        1.0|\n",
      "|        0.0|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select( (  (col(\"sequences.counts.correct\")/col(\"sequences.counts.total\")).alias(\"pct_correct\"))).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. How many unique exams are offered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT exam_name)|\n",
      "+-------------------------+\n",
      "|                      103|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.select(countDistinct(\"exam_name\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. What percent of assessments are certified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of assessments with certification == 'false' = 3148\n",
      "Number of assessments with certification == 'NULL' = 132\n",
      "Total assessment = 3280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "null_assess = assessments_df.filter(assessments_df[\"certification\"].isNull()).select('certification').count()\n",
    "false_assess = assessments_df.filter(assessments_df[\"certification\"] == 'false').select('certification').count()\n",
    "total_assess = assessments_df.count()\n",
    "\n",
    "print(\"Number of assessments with certification == 'false' =\", false_assess)\n",
    "print(\"Number of assessments with certification == 'NULL' =\", null_assess)\n",
    "print(\"Total assessment =\", total_assess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the 'certification' field is either 'false' or NULL. So '0%' of assessments in the database are for certified assessments. In the ordinary course of work, I'd dig deeper to determine if this is a worthwhile field to keep. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### WRITING TO HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll redisplay the schema to discuss what we'll write to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- certification: string (nullable = true)\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- keen_created_at: string (nullable = true)\n",
      " |-- keen_id: string (nullable = true)\n",
      " |-- keen_timestamp: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: long (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: long (nullable = true)\n",
      " |    |    |-- incomplete: long (nullable = true)\n",
      " |    |    |-- incorrect: long (nullable = true)\n",
      " |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |-- total: long (nullable = true)\n",
      " |    |    |-- unanswered: long (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- user_submitted: boolean (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- user_exam_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### We'll redisplay the schema to discuss what we'll write to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- I'll write all the top level nodes to one table and add a percent correct column\n",
    "- I'll write all the members of sequences.counts to a separate table\n",
    "- I'll write sequences.questions.id to a third table\n",
    "\n",
    "For all the tables, I'll include user_exam_id as a key that they can be joined on. This is a little problematic because, as I mentioned earlier, this field isn't completely unique. In a real world environment I'd clean that column up or create a new unique id. \n",
    "\n",
    "For sequencies.questions.id, I'll write this as single column of arrays. With more time, I'd write this as three columns: user_exam_id, the sequence number of the item in the array and the id itself in a third column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_df = assessments_df.select('user_exam_id', 'base_exam_id', 'certification', 'exam_name', 'keen_created_at', \\\n",
    "                                  'keen_id', 'keen_timestamp', 'max_attempts', 'started_at',\n",
    "                                 (col(\"sequences.counts.correct\")/col(\"sequences.counts.total\")).alias(\"pct_correct\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = assessments_df.select('user_exam_id', 'sequences.counts.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------+----------+---------+---------+-----+----------+\n",
      "|        user_exam_id|all_correct|correct|incomplete|incorrect|submitted|total|unanswered|\n",
      "+--------------------+-----------+-------+----------+---------+---------+-----+----------+\n",
      "|6d4089e4-bde5-4a2...|      false|      2|         1|        1|        4|    4|         0|\n",
      "|2fec1534-b41f-441...|      false|      1|         2|        1|        4|    4|         0|\n",
      "|8edbc8a8-4d26-429...|      false|      3|         0|        1|        4|    4|         0|\n",
      "|c0ee680e-8892-4e6...|      false|      2|         2|        0|        4|    4|         0|\n",
      "|e4525b79-7904-405...|      false|      3|         0|        1|        4|    4|         0|\n",
      "|3186dafa-7acf-47e...|       true|      5|         0|        0|        5|    5|         0|\n",
      "|48d88326-36a3-4cb...|       true|      1|         0|        0|        1|    1|         0|\n",
      "|bb152d6b-cada-41e...|       true|      5|         0|        0|        5|    5|         0|\n",
      "|70073d6f-ced5-4d0...|       true|      4|         0|        0|        4|    4|         0|\n",
      "|9eb6d4d6-fd1f-4f3...|      false|      0|         1|        0|        1|    5|         4|\n",
      "|093f1337-7090-457...|      false|      3|         1|        0|        4|    4|         0|\n",
      "|0f576abb-958a-4c0...|       true|      1|         0|        0|        1|    1|         0|\n",
      "|0c18f48c-0018-450...|      false|      4|         1|        1|        6|    6|         0|\n",
      "|b38ac9d8-eef9-495...|      false|      4|         0|        2|        6|    6|         0|\n",
      "|bbc9865f-88ef-42e...|      false|      4|         1|        0|        5|    5|         0|\n",
      "|8a0266df-02d7-44e...|      false|      3|         0|        1|        4|    4|         0|\n",
      "|95d4edb1-533f-445...|      false|      3|         0|        0|        3|    4|         1|\n",
      "|f9bc1eff-7e54-42a...|       true|      4|         0|        0|        4|    4|         0|\n",
      "|dc4b35a7-399a-4bd...|      false|      2|         0|        0|        2|    4|         2|\n",
      "|d0f8249a-597e-4e1...|       true|      6|         0|        0|        6|    6|         0|\n",
      "+--------------------+-----------+-------+----------+---------+---------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_id_df = assessments_df.select('user_exam_id', 'sequences.questions.id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|        user_exam_id|                  id|\n",
      "+--------------------+--------------------+\n",
      "|6d4089e4-bde5-4a2...|[7a2ed6d3-f492-49...|\n",
      "|2fec1534-b41f-441...|[95194331-ac43-45...|\n",
      "|8edbc8a8-4d26-429...|[b9ff2e88-cf9d-4b...|\n",
      "|c0ee680e-8892-4e6...|[1f7c5def-904b-48...|\n",
      "|e4525b79-7904-405...|[620c924f-6bd8-11...|\n",
      "|3186dafa-7acf-47e...|[fb07b16e-84a2-46...|\n",
      "|48d88326-36a3-4cb...|[247b4589-7f8c-4a...|\n",
      "|bb152d6b-cada-41e...|[fc3bdc54-04a8-4b...|\n",
      "|70073d6f-ced5-4d0...|[803fc93f-7eb2-41...|\n",
      "|9eb6d4d6-fd1f-4f3...|[fc3bdc54-04a8-4b...|\n",
      "|093f1337-7090-457...|[a6effaf7-94ba-45...|\n",
      "|0f576abb-958a-4c0...|[247b4589-7f8c-4a...|\n",
      "|0c18f48c-0018-450...|[0d12c14d-1abe-4b...|\n",
      "|b38ac9d8-eef9-495...|[26ddad33-aa1d-49...|\n",
      "|bbc9865f-88ef-42e...|[7bdbbf4a-b5d8-4c...|\n",
      "|8a0266df-02d7-44e...|[d2ac7f0d-82bd-41...|\n",
      "|95d4edb1-533f-445...|[59d444b5-49fd-48...|\n",
      "|f9bc1eff-7e54-42a...|[e272a3d1-bd67-4d...|\n",
      "|dc4b35a7-399a-4bd...|[dee14932-a24e-4a...|\n",
      "|d0f8249a-597e-4e1...|[861c3405-83fc-42...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_id_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
